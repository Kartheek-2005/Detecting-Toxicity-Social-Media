{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4919c285-bdc4-43df-a311-ddbcd1f1ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e98716-8d95-47c6-8523-ba92e1cfa379",
   "metadata": {},
   "source": [
    "### ToxiGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057d99d4-f546-462e-927e-9cb35c73c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples taked from ToxiGen-Demonstrations: 654\n",
      "Overall dimensions of the ToxiGen dataset:\n",
      "\t Train: (9546, 2)\n",
      "\t Test: (940, 2)\n",
      "\t Unique values in the 'label' column: [0.0, 0.08, 0.17, 0.25, 0.33, 0.42, 0.5, 0.58, 0.67, 0.75, 0.83, 0.92, 1.0]\n"
     ]
    }
   ],
   "source": [
    "root_dir1 = 'original/ToxiGen/demonstrations'\n",
    "root_dir2 = 'original/ToxiGen/annotated'\n",
    "\n",
    "df_toxigen = []\n",
    "\n",
    "for f_name in os.listdir(root_dir1):\n",
    "    if f_name.startswith('hate'):\n",
    "        f = open(f\"{root_dir1}/{f_name}\", 'r')\n",
    "        texts = [text for text in f.read().split('\\n')]\n",
    "        # print(\"hate\", len(texts))\n",
    "        df_toxigen += [[text, 1.0] for text in texts]\n",
    "    elif f_name.startswith('neutral'): \n",
    "        f = open(f\"{root_dir1}/{f_name}\", 'r')\n",
    "        texts = [text for text in f.read().split('\\n')]\n",
    "        # print(\"neutral\", len(texts))\n",
    "        df_toxigen += [[text, 0.0] for text in texts]\n",
    "\n",
    "print(f'Number of examples taked from ToxiGen-Demonstrations: {len(df_toxigen)}')\n",
    "\n",
    "pq_train = pq.read_table(f'{root_dir2}/train-00000-of-00001.parquet')\n",
    "pq_test = pq.read_table(f'{root_dir2}/test-00000-of-00001.parquet')\n",
    "df_train = pq_train.to_pandas()\n",
    "df_test = pq_test.to_pandas()\n",
    "\n",
    "df_train = df_train.loc[:, ['text', 'toxicity_human']]\n",
    "df_test = df_test.loc[:, ['text', 'toxicity_human']]\n",
    "min_val = min(np.min(df_train['toxicity_human']), np.min(df_test['toxicity_human']))\n",
    "max_val = max(np.max(df_train['toxicity_human']), np.max(df_test['toxicity_human']))\n",
    "df_train['toxicity_human'] = np.round((df_train['toxicity_human'] - min_val) / (max_val - min_val), 2)\n",
    "df_test['toxicity_human'] = np.round((df_test['toxicity_human'] - min_val) / (max_val - min_val), 2)\n",
    "\n",
    "df_train = pd.DataFrame(df_toxigen + df_train.values.tolist(), columns=['text', 'label'])\n",
    "df_test = df_test.rename(columns={'toxicity_human': 'label'})\n",
    "\n",
    "df_train = df_train.drop_duplicates().reset_index(drop=True)\n",
    "df_test = df_test.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Overall dimensions of the ToxiGen dataset:\")\n",
    "print(f\"\\t Train: {df_train.shape}\")\n",
    "print(f\"\\t Test: {df_test.shape}\")\n",
    "print(f\"\\t Unique values in the 'label' column: {sorted(list(set(list(df_train['label'].values) + list(df_test['label'].values))))}\")\n",
    "\n",
    "df_train.to_csv('processed/ToxiGen/train.csv', index=False)\n",
    "df_test.to_csv('processed/ToxiGen/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b27698-570b-4951-b290-e8b47ada841c",
   "metadata": {},
   "source": [
    "### SBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492f20a4-9bbc-4709-af03-c111932939de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall dimensions of the SBIC dataset:\n",
      "\t Train: (35424, 2)\n",
      "\t Validation: (4666, 2)\n",
      "\t Test: (4691, 2)\n",
      "\t Unique values in the 'label' column: [0.0, 0.08, 0.1, 0.12, 0.17, 0.2, 0.25, 0.3, 0.33, 0.38, 0.4, 0.42, 0.43, 0.5, 0.57, 0.58, 0.6, 0.62, 0.64, 0.67, 0.7, 0.71, 0.72, 0.73, 0.75, 0.77, 0.78, 0.79, 0.8, 0.81, 0.83, 0.86, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sbic(df: pd.DataFrame):\n",
    "    df = df.rename(columns={'post': 'text', 'offensiveYN': 'label'})\n",
    "    df['label'] = np.round(df['label'], 2)\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_train = preprocess_sbic(pd.read_csv('original/SBIC/SBIC.v2.agg.trn.csv')[['post', 'offensiveYN']])\n",
    "df_dev = preprocess_sbic(pd.read_csv('original/SBIC/SBIC.v2.agg.dev.csv')[['post', 'offensiveYN']])\n",
    "df_test = preprocess_sbic(pd.read_csv('original/SBIC/SBIC.v2.agg.tst.csv')[['post', 'offensiveYN']])\n",
    "\n",
    "print(f\"Overall dimensions of the SBIC dataset:\")\n",
    "print(f\"\\t Train: {df_train.shape}\")\n",
    "print(f\"\\t Validation: {df_dev.shape}\")\n",
    "print(f\"\\t Test: {df_test.shape}\")\n",
    "print(f\"\\t Unique values in the 'label' column: {sorted(list(set(list(df_train['label'].values) + list(df_dev['label'].values) + list(df_test['label'].values))))}\")\n",
    "\n",
    "df_train.to_csv('processed/SBIC/train.csv', index=False)\n",
    "df_dev.to_csv('processed/SBIC/validation.csv', index=False)\n",
    "df_test.to_csv('processed/SBIC/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe928b3-d9b9-468f-8a6e-3492be607283",
   "metadata": {},
   "source": [
    "### DHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63de301-c2fb-403a-be39-71f9ec3a0ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skart\\AppData\\Local\\Temp\\ipykernel_22272\\2570839767.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['label'] = df['label'].replace({'hate': 1.0, 'nothate': 0.0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall dimensions of the DHate dataset:\n",
      "\t Train: (32924, 3)\n",
      "\t Validation: (4100, 3)\n",
      "\t Test: (4120, 3)\n",
      "\t Unique values in the 'label' column: [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dhate(df: pd.DataFrame):\n",
    "    df['label'] = df['label'].replace({'hate': 1.0, 'nothate': 0.0})\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('original/DHate/Dynamically Generated Hate Dataset v0.2.3.csv')[['text', 'label', 'split']]\n",
    "df = preprocess_dhate(df)\n",
    "\n",
    "df_train = df[df['split'] == 'train']\n",
    "df_dev = df[df['split'] == 'dev']\n",
    "df_test = df[df['split'] == 'test']\n",
    "\n",
    "df_train.drop(columns=['split'], axis=1)\n",
    "df_dev.drop(columns=['split'], axis=1)\n",
    "df_test.drop(columns=['split'], axis=1)\n",
    "\n",
    "print(f\"Overall dimensions of the DHate dataset:\")\n",
    "print(f\"\\t Train: {df_train.shape}\")\n",
    "print(f\"\\t Validation: {df_dev.shape}\")\n",
    "print(f\"\\t Test: {df_test.shape}\")\n",
    "print(f\"\\t Unique values in the 'label' column: {sorted(list(set(list(df_train['label'].values) + list(df_dev['label'].values) + list(df_test['label'].values))))}\")\n",
    "\n",
    "df_train.to_csv('processed/DHate/train.csv', index=False)\n",
    "df_dev.to_csv('processed/DHate/validation.csv', index=False)\n",
    "df_test.to_csv('processed/DHate/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
