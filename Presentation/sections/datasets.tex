\section{Datasets}

\begin{frame}{Datasets}

  \begin{itemize}
  
    \item ToxicGen
    \begin{itemize}
      \item Created by prompting an LLM to produce toxic and benign texts.
      \item Texts do not contain explicit language and target minority groups.
      \item Example: Muslims deserve to die.
    \end{itemize}
    
    \item SBIC (Social Bias Inference Corpus):
    \begin{itemize}
      \item Texts contain stereotypes and offensiveness towards an individual or a group of people.
      \item Example: Women candidates are less qualified.
    \end{itemize}

    \item DHate
    \begin{itemize}
      \item Details about this dataset are not revealed.
      \item From manual analysis, this dataset seems to be comprised of hate of minorities.
      \item Example: I always feel unsafe when surrounded by Arabs.
    \end{itemize}

  \end{itemize}
    
\end{frame}
