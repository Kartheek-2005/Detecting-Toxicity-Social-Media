%% Datasets %%

% ToxiGen
@inproceedings{hartvigsen2022toxigen,
  title={ToxiGen: A Large-Scale Machine-Generated Dataset for Implicit and Adversarial Hate Speech Detection},
  author={Hartvigsen, Thomas and Gabriel, Saadia and Palangi, Hamid and Sap, Maarten and Ray, Dipankar and Kamar, Ece},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  year={2022}
}

% DHate
@article{vidgen2020learning,
  title={Learning from the worst: Dynamically generated datasets to improve online hate detection},
  author={Vidgen, Bertie and Thrush, Tristan and Waseem, Zeerak and Kiela, Douwe},
  journal={arXiv preprint arXiv:2012.15761},
  year={2020},
  url="https://arxiv.org/abs/2012.15761"
}

% BD-LLM
@inproceedings{zhang2024efficient,
  title={Efficient toxic content detection by bootstrapping and distilling large language models},
  author={Zhang, Jiang and Wu, Qiong and Xu, Yiming and Cao, Cheng and Du, Zheng and Psounis, Konstantinos},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={21779--21787},
  year={2024}
}


%% Literature %%

% RoBERTa
@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan},
  journal={arXiv preprint arXiv:1907.11692},
  volume={364},
  year={2019},
  url="https://arxiv.org/abs/1907.11692"
}
