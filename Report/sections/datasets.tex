\section{Datasets}

The datasets we will use in this study are:


\subsection{ToxicGen}

Introduced by \citet{hartvigsen2022toxigen}, this dataset is created by prompting an LLM to produce toxic and benign texts.
The texts in this dataset do not include explicit language and target minority groups.
An example of a text labelled as toxic is "Muslims deserve to die".


\subsection{SBIC (Social Bias Inference Corpus)}

Introduced by \citet{sap2020socialbiasframes}, texts in this dataset contain stereotypes or offensiveness towards an individual or a group of people.
Warning: this dataset contains explicit and sensitive language.
An example of a text labelled as toxic is "Women candidates are less qualified".


\subsection{DHate}

This dataset is introduced by \citet{vidgen2020learning}.
Its details are not publicly available.
From manual analysis, this dataset mainly comprises of hate of minority groups.
Warning: this dataset contains explicit and sensitive language.
An example of a text labelled as toxic is "I always feel unsafe when surrounded by Arabs".
